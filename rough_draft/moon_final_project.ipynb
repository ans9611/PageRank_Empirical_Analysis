{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithm description\n",
    "- Algorithm code\n",
    "- Empirical and canonical test dataset\n",
    "- Performance measures (analytical and empirical)\n",
    "- Evaluation\n",
    "- Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                                        ¬© Moon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report: Evaluation of the Centrality Algorithm, PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality algorithms are one of the categories of graph algorithms. They identify the important nodes in a given graph and those nodes are defined as vertices with many direct or indirect connections.  One of the centrality algorithms is called $PageRank(PR)$ which identify most important vertices of a graph by measuring the direct influence of nodes based on proportional rank.  [2]PR is invented by Larray Page and used by Google Search to rank web pages in their search engine results.\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Simplified algorithm of the PageRank\n",
    "- Implementation the PageRank algorithm and explore it on graphs of social networks available in Networks.\n",
    "- Measuring time complexity theoretically\n",
    "- Measuring time complexity empirically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Original Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]The PageRank algorithm returns the probability that a person randomly surfing will arrive arrive at any particular page. It is assumed that the input distribution is evenly divided at the beginning of PR process. \n",
    "\n",
    "PR takes three inputs; number of pages, damping factor, and a number of iterations. The PageRank relies on an arbitrary probability distribution in which a person randomly clicks on links will arrive at any particular page. The probability which a person independently will continue is a damping fator d. PR computations require iterations through a number of pages to adjust approximate PR values to the theoretical value.\n",
    "\n",
    "The result of node with a PR of 0.4 for instance, means there is 40% chance that a person randomly surf will be directed to the node.\n",
    "\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The iteration equation of the page rank value of  ùëñ  is given by\n",
    "\n",
    "**PR(n) = (1-d)/N + d*(PR(n1)/num_neighbors(n1) + ... + PR(n_last)/num_neighbors(n_last))**\n",
    "\n",
    "where the damping factor $d=D$, $\\frac{d}{n}$ denotes random walk score, $OutputDegree(P_j)$ denote how many pages are linked as children pages for the page $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PageRank: Link Anaylsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Steps:\n",
    "1. Initialize the PageRank of every node with a value of 1/n\n",
    "2. Iterate through the graph. For each iteration, update the PageRank of every node in the graph.\n",
    "   1. For the first page, it only processes through random walk. \n",
    "   2. For other pages, they can process through random walk or inter-page links. \n",
    "   3. Sum up the proportional rank from all of its in-neighbors\n",
    "   4. Update the PageRank with the weighted sum of proportional rank and random walk\n",
    "3. Normalize the PageRank when there is terminal point. PageRank value will converge after enough iterations\n",
    "5. Return Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithm Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Direct Iteration Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from time import perf_counter\n",
    "np.set_printoptions(precision=3)  # the precision to print\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028 0.051 0.071 0.088 0.102 0.114 0.125 0.134 0.141 0.147]\n"
     ]
    }
   ],
   "source": [
    "# n = 6  # the number of nodes or pages\n",
    "# d = 0.15  # damping factor\n",
    "# T = 1  # the number of iteration\n",
    "\n",
    "def pageRank(n, d, T):\n",
    "    # Step 1: Initialize the PageRank of every node with a value of 1/n | O(n)\n",
    "    PR = np.ones(n)/n\n",
    "\n",
    "    # Step 2: For each iteration, update the PageRank of every node in the graph.\n",
    "    for i_t in range(T):  # O(k) where k is number of iteration\n",
    "        \n",
    "        # 2-1: For the first page, it only processes through random walk. \n",
    "        rand = 1 / n  # assign value: O(1)\n",
    "        PR[0] = d * rand  # assign value & computation: O(1)\n",
    "\n",
    "        #  2-2: For other pages, they can process through random walk or inter-page links.\n",
    "        for i in range(1, n):  # O(n) where n is number of pages\n",
    "            \n",
    "            # 2 - 3: Sum up the proportional rank from all of its in-neighbors \n",
    "            i_prop = PR[i-1] / 1 # assign value & computation: O(1)\n",
    "            # 2 - 4: Update the PageRank with the weighted sum of proportional rank and random walk\n",
    "            PR[i] = d * rand + (1-d) * i_prop # assign value & computation: O(1)\n",
    "\n",
    "# Step 3: normalize PR when there is terminal point\n",
    "    PR /= PR.sum()  # assign value & computation: O(1)\n",
    "    return PR # returning value: O(1)\n",
    "\n",
    "\n",
    "print(pageRank(10, 0.15, 50010))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# # Generate Networkx Graph\n",
    "# G = nx.Graph()\n",
    "# G.add_nodes_from(nodes)\n",
    "\n",
    "# # randomly determine vertices\n",
    "# for (node1, node2) in itertools.combinations(nodes, 2):\n",
    "#     if random.random() < 0.5:\n",
    "#         G.add_edge(node1, node2)\n",
    "\n",
    "# # Draw generated graph\n",
    "# nx.draw_networkx(G, pos=nx.circular_layout(G), with_labels=True)\n",
    "\n",
    "\n",
    "# # Compute Page Rank\n",
    "# output = nx.pagerank(G, alpha=0.85)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028 0.051 0.071 0.088 0.102 0.114 0.125 0.134 0.141 0.147]\n"
     ]
    }
   ],
   "source": [
    "#[3]\n",
    "# Create a scale-free graph on one hundred nodes:\n",
    "G = nx.scale_free_graph(10)\n",
    "n = nx.number_of_nodes(G)\n",
    "d = 0.15\n",
    "T = 100\n",
    "\n",
    "print(pageRank(n, d, T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 100 nodes and 205 edges\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank Implementation on other graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Runs the PageRank algorithm on a directed or undirected graph of the data.\n",
    "2. Iterate through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time and space complexity of the clustering algorithm.\n",
    "\n",
    "Refer to the algorithm and the script in the previous cells.\n",
    "\n",
    "The main loop runs N times.\n",
    "The inner loop runs K times, which is the number of clusters generated\n",
    "Worst case: N clusters are generated, \n",
    "O\n",
    "(\n",
    "n\n",
    "2\n",
    ")\n",
    " complexity\n",
    "\n",
    "Average case: K clusters are generated, \n",
    "K\n",
    "<<\n",
    "N\n",
    ", and then \n",
    "O\n",
    "(\n",
    "n\n",
    ")\n",
    " complexity\n",
    "\n",
    "Space complexity is \n",
    "O\n",
    "(\n",
    "K\n",
    ")\n",
    " + \n",
    "O\n",
    "(\n",
    "n\n",
    ")\n",
    " since we keep only the cluster information, i.e. centroids and cluster assignment for each data point \n",
    "x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of operations by a counter is the most accurate way of empirical analysis of a function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this study, we analyzed a clustering algorithm for its theoretical and empirical complexity.\n",
    "\n",
    "Clustering algorithms are important members of unsupervised learning algorithms. In this study, we examined the single-pass clustering algorithm as a streaming, big data analytic. We empirically showed that the algorithm can run in \n",
    "O\n",
    "(\n",
    "n\n",
    ")\n",
    " time and therefore it can be used in streaming big data applications.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Your evaluations and conclusions must be much more detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rajat95gupta. ‚ÄúImplementing PageRank on Famous Social Networks.‚Äù Kaggle.com, Kaggle, 29 Dec. 2021, www.kaggle.com/code/rajat95gupta/implementing-pagerank-on-famous-social-networks. <br>\n",
    "Wikipedia Contributors. ‚ÄúPageRank.‚Äù Wikipedia, Wikimedia Foundation, 23 July 2022, en.wikipedia.org/wiki/PageRank. Accessed 24 July 2022.\n",
    "‚ÄúScale_free_graph ‚Äî NetworkX 2.8.5 Documentation.‚Äù Networkx.org, 2022, networkx.org/documentation/stable/reference/generated/networkx.generators.directed.scale_free_graph.html#networkx.generators.directed.scale_free_graph. Accessed 24 July 2022.\n",
    "\n",
    "‚Äå\n",
    "\n",
    "‚Äå\n",
    "\n",
    "\n",
    "‚Äå"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baa2e52980430d335b97b133b9bdc90c6ba1b985616caf224317f930da22a067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
