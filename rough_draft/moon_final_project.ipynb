{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Algorithm description\n",
    "- Algorithm code\n",
    "- Empirical and canonical test dataset\n",
    "- Performance measures (analytical and empirical)\n",
    "- Evaluation\n",
    "- Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                                        © Moon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report: Evaluation of the Centrality Algorithm, PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality algorithms are one of the categories of graph algorithms. They identify the important nodes in a given graph and those nodes are defined as vertices with many direct or indirect connections.  One of the centrality algorithms is called $PageRank(PR)$ which identify most important vertices of a graph by measuring the direct influence of nodes based on proportional rank.  [2]PR is invented by Larray Page and used by Google Search to rank web pages in their search engine results.\n",
    "\n",
    "This notebook demonstrates:\n",
    "- The PageRank algorithm\n",
    "- Implementation the Classic PageRank algorithm and explore it on graphs generated from Networks, python library.\n",
    "- Measuring time complexity theoretically\n",
    "- Measuring time complexity empirically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] ```PageRank is a link analysis algorithm and it assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of \"measuring\" its relative importance within the set.```\n",
    ".The PageRank algorithm returns the probability that a person randomly surfing will arrive arrive at any particular page. It is assumed that the input distribution is evenly divided at the beginning of PR process. \n",
    "\n",
    "PR takes three inputs; number of pages, damping factor, and a number of iterations. The PageRank relies on an arbitrary probability distribution in which a person randomly clicks on links will arrive at any particular page. The probability which a person independently will continue is a damping fator d. PR computations require iterations through a number of pages to adjust approximate PR values to the theoretical value.\n",
    "\n",
    "The result of node with a PR of 0.4 for instance, means there is 40% chance that a person randomly surf will be directed to the node.\n",
    "\n",
    "The implementation of the classic PageRank algorithm uses an iterative method. At each iteration step, the PageRank value of all nodes in the graph are computed.\n",
    "\n",
    "### PageRank Formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The iteration equation of the page rank value of  𝑖  is given by\n",
    "\n",
    "**PR(n) = (1-d)/N + d*(PR(n1)/num_neighbors(n1) + ... + PR(n_last)/num_neighbors(n_last))**\n",
    "\n",
    "where the damping factor $d=D$, $\\frac{d}{n}$ denotes random walk score, $OutputDegree(P_j)$ denote how many pages are linked as children pages for the page $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Steps\n",
    "The implementation of the classic PageRank algorithm uses an iterative method. At each iteration step, the PageRank value of all nodes in the graph are computed.\n",
    "\n",
    "1. Initialize the PageRank of every node with a value of 1/n\n",
    "2. Iterate through the graph. For each iteration, update the PageRank of every node in the graph.\n",
    "   1. For the first page, it only processes through random walk. \n",
    "   2. For other pages, they can process through random walk or inter-page links. \n",
    "   3. Sum up the proportional rank from all of its in-neighbors\n",
    "   4. Update the PageRank with the weighted sum of proportional rank and random walk\n",
    "3. Normalize the PageRank when there is terminal point. PageRank value will converge after enough iterations\n",
    "5. Return Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Algorithm Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Input Argument** | **Type** | **Comment**                                       | \n",
    "|--------------------|----------|---------------------------------------------------|\n",
    "| G                  | graph    | input graph; will be converted to number of nodes |\n",
    "| n                  | int      | total number of nodes of given graph (G)          |     \n",
    "| d                  | float    | damping factor                                    |\n",
    "| I                  | int    | the number of iteration                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Output Argument** | **Type** | **Comment**                                                           |\n",
    "|---------------------|----------|-----------------------------------------------------------------------|\n",
    "| PR                  | array    | node property where the PageRank value for each node will be written. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from time import perf_counter\n",
    "np.set_printoptions(precision=3)  # the precision to print\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028 0.051 0.071 0.088 0.102 0.114 0.125 0.134 0.141 0.147]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nReferences\\n----------\\n[1]“Networkx.algorithms.link_analysis.pagerank_alg — NetworkX 2.8.5 Documentation.” \\nNetworkx.org, 2022, networkx.org/documentation/stable/_modules/networkx/algorithms/link_analysis/pagerank_alg.html#pagerank. \\nAccessed 24 July 2022.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pageRank(n, d, I):\n",
    "    # Step 1: Initialize the PageRank of every node with a value of 1/n | O(n)\n",
    "    PR = np.ones(n)/n\n",
    "\n",
    "    # Step 2: For each iteration, update the PageRank of every node in the graph.\n",
    "    for i_t in range(I):  # O(k) where k is number of iteration\n",
    "        \n",
    "        # 2-1: For the first page, it only processes through random walk. \n",
    "        rand = 1 / n  # assign value: O(1)\n",
    "        PR[0] = d * rand  # assign value & computation: O(1)\n",
    "\n",
    "        #  2-2: For other pages, they can process through random walk or inter-page links.\n",
    "        for i in range(1, n):  # O(n) where n is number of pages\n",
    "            \n",
    "            # 2 - 3: Sum up the proportional rank from all of its in-neighbors \n",
    "            i_prop = PR[i-1] / 1 # assign value & computation: O(1)\n",
    "            # 2 - 4: Update the PageRank with the weighted sum of proportional rank and random walk\n",
    "            PR[i] = d * rand + (1-d) * i_prop # assign value & computation: O(1)\n",
    "\n",
    "# Step 3: normalize PR when there is terminal point\n",
    "    PR /= PR.sum()  # assign value & computation: O(1)\n",
    "    return PR # returning value: O(1)\n",
    "\n",
    "\n",
    "# print(pageRank(10, 0.15, 50010))\n",
    "'''\n",
    "References\n",
    "----------\n",
    "[1]“Networkx.algorithms.link_analysis.pagerank_alg — NetworkX 2.8.5 Documentation.” \n",
    "Networkx.org, 2022, networkx.org/documentation/stable/_modules/networkx/algorithms/link_analysis/pagerank_alg.html#pagerank. \n",
    "Accessed 24 July 2022.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThen, we can use adjacency matrix to calculate the transition probability matrix  𝑃 , which is the row-wise normalized adjacency matrix.  𝑃(𝑖,𝑗)  denotes the probability of the transition from  𝑖  to  𝑗 .\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global parameters\n",
    "n = 6\n",
    "\n",
    "# initialize adjacency matrix\n",
    "M = np.zeros([n, n])\n",
    "# add links of page 1 -> 2\n",
    "M[0, 1] = 1\n",
    "# add links of page 2 -> 3\n",
    "M[1, 2] = 1\n",
    "# add links of page 3 -> 4\n",
    "M[2, 3] = 1\n",
    "# add links of page 4 -> 5\n",
    "M[3, 4] = 1\n",
    "# add links of page 5 -> 6\n",
    "M[4, 5] = 1\n",
    "# add links of page 6 -> all\n",
    "M[5, :] = 1\n",
    "# show the matrix\n",
    "print(M)\n",
    "\n",
    "\n",
    "'''\n",
    "Then, we can use adjacency matrix to calculate the transition probability matrix  𝑃 , which is the row-wise normalized adjacency matrix.  𝑃(𝑖,𝑗)  denotes the probability of the transition from  𝑖  to  𝑗 .\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row sum of M:\n",
      " [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [6.]]\n",
      "transition matrix of M:\n",
      " [[0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.    0.   ]\n",
      " [0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.    0.    1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    1.   ]\n",
      " [0.167 0.167 0.167 0.167 0.167 0.167]]\n"
     ]
    }
   ],
   "source": [
    "# by row sum of M (aggregate the second dimension: column)\n",
    "M_rowsum = np.sum(M, 1, keepdims=True)\n",
    "print(f'row sum of M:\\n {M_rowsum}')\n",
    "\n",
    "# transition matrix\n",
    "P = M / M_rowsum\n",
    "print(f'transition matrix of M:\\n {P}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is a probability  𝑑  of random walk. Thus, the expected transition matrix  𝑃̂   is the weighted average of  𝑃  and random walk probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the expected transition matrix:\n",
      " [[0.025 0.875 0.025 0.025 0.025 0.025]\n",
      " [0.025 0.025 0.875 0.025 0.025 0.025]\n",
      " [0.025 0.025 0.025 0.875 0.025 0.025]\n",
      " [0.025 0.025 0.025 0.025 0.875 0.025]\n",
      " [0.025 0.025 0.025 0.025 0.025 0.875]\n",
      " [0.167 0.167 0.167 0.167 0.167 0.167]]\n"
     ]
    }
   ],
   "source": [
    "# the probability of random walk (damping factor)\n",
    "d = 0.15\n",
    "\n",
    "# the probability of being reached if random walk\n",
    "rand = 1 / n\n",
    "\n",
    "# the expected transition matrix\n",
    "P_hat = P * (1 - d) + rand * d\n",
    "\n",
    "print(f'the expected transition matrix:\\n {P_hat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028 0.051 0.071 0.088 0.102 0.114 0.125 0.134 0.141 0.147]\n"
     ]
    }
   ],
   "source": [
    "#[3]\n",
    "# Create a scale-free graph on one hundred nodes:\n",
    "G = nx.scale_free_graph(10)\n",
    "n = nx.number_of_nodes(G)\n",
    "d = 0.15\n",
    "T = 100\n",
    "\n",
    "print(pageRank(n, d, T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiGraph with 100 nodes and 205 edges\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Runs the PageRank algorithm on a directed or undirected graph of the data.\n",
    "2. Iterate through "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Time and space complexity of the classic PageRank algorithm. The implementation of this algorithm uses an iterative method. At each iteration step, the PageRank value of all nodes in the graph are computed. <br>\n",
    "\n",
    "\n",
    "Refer to the algorithm and the script in the previous cells. <br>\n",
    "\n",
    "The main loop runs I times, which is total number of iteration. <br>\n",
    "The inner loop runs n times, which is the number of nodes generated <br>\n",
    "<br>\n",
    "\n",
    "The time complexity’s value is O(I * n) where I represents the specific number of iterations that needs to be run on node n. \n",
    "\n",
    "The big O value for PageRank’s space complexity is O(N) where n is total number of nodes. since we keep only the given nodes information. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of operations by a counter is the most accurate way of empirical analysis of a function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this study, we analyzed a PageRank algorithm for its theoretical and empirical complexity.\n",
    "\n",
    "PageRank algorithms are important members of unsupervised learning algorithms. In this study, we examined the single-pass clustering algorithm as a streaming, big data analytic. We empirically showed that the algorithm can run in \n",
    "O(N * K) time and therefore it can be used in streaming big data applications.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: Your evaluations and conclusions must be much more detailed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rajat95gupta. “Implementing PageRank on Famous Social Networks.” Kaggle.com, Kaggle, 29 Dec. 2021, www.kaggle.com/code/rajat95gupta/implementing-pagerank-on-famous-social-networks. <br>\n",
    "Wikipedia Contributors. “PageRank.” Wikipedia, Wikimedia Foundation, 23 July 2022, en.wikipedia.org/wiki/PageRank. Accessed 24 July 2022.\n",
    "“Scale_free_graph — NetworkX 2.8.5 Documentation.” Networkx.org, 2022, networkx.org/documentation/stable/reference/generated/networkx.generators.directed.scale_free_graph.html#networkx.generators.directed.scale_free_graph. Accessed 24 July 2022.\n",
    "“Networkx.algorithms.link_analysis.pagerank_alg — NetworkX 2.8.5 Documentation.” Networkx.org, 2022, networkx.org/documentation/stable/_modules/networkx/algorithms/link_analysis/pagerank_alg.html#pagerank. Accessed 24 July 2022.\n",
    "\n",
    "‌\n",
    "‌\n",
    "\n",
    "‌\n",
    "\n",
    "\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baa2e52980430d335b97b133b9bdc90c6ba1b985616caf224317f930da22a067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
